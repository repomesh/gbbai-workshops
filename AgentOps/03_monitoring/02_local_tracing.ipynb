{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b21e4682",
   "metadata": {},
   "source": [
    "# Azure OpenAI Local Tracing with SQLite\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook demonstrates **local tracing for Azure OpenAI API calls** using OpenTelemetry and SQLite storage. Unlike cloud-based tracing with Application Insights, this approach stores traces locally for offline development, testing, and debugging.\n",
    "\n",
    "### What is Local Tracing?\n",
    "\n",
    "Local tracing captures detailed telemetry about Azure OpenAI API interactions and stores them in a local SQLite database. This enables:\n",
    "\n",
    "- **Offline Development**: No Azure dependencies for tracing\n",
    "- **Cost-Effective Testing**: No Application Insights charges\n",
    "- **Privacy**: All data stays on your machine\n",
    "- **Fast Queries**: Direct SQL access to trace data\n",
    "- **Debugging**: Detailed inspection of API calls and responses\n",
    "\n",
    "### Key Features\n",
    "\n",
    "**Custom Tracing Utilities:**\n",
    "- Wrapper functions for synchronous and asynchronous API calls\n",
    "- Built-in support for streaming responses\n",
    "- Automatic span creation with semantic conventions\n",
    "- SQLite storage with structured schema\n",
    "\n",
    "**Captured Telemetry:**\n",
    "- Request parameters (model, temperature, max_tokens, etc.)\n",
    "- Full prompts and completions (configurable)\n",
    "- Token usage (prompt, completion, total)\n",
    "- Latency metrics (milliseconds)\n",
    "- Error tracking and exceptions\n",
    "- Streaming chunk counts\n",
    "\n",
    "**SQLite Database:**\n",
    "- Two tables: `spans` and `span_attributes`\n",
    "- Foreign key relationships for data integrity\n",
    "- Queryable with standard SQL\n",
    "- Pandas integration for analysis\n",
    "\n",
    "**Flexible Configuration:**\n",
    "- Console output (optional)\n",
    "- Batch vs immediate span processing\n",
    "- Custom database paths\n",
    "- Verbose logging control\n",
    "\n",
    "### Tracing Workflow\n",
    "\n",
    "```\n",
    "1. Setup Tracing (SQLite + OpenTelemetry)\n",
    "   â†“\n",
    "2. Initialize Azure OpenAI Clients\n",
    "   â†“\n",
    "3. Make API Calls with Traced Wrappers\n",
    "   â†“\n",
    "4. Traces Stored in Local SQLite DB\n",
    "   â†“\n",
    "5. Query with SQL/Pandas\n",
    "   â†“\n",
    "6. Analyze Performance & Debug Issues\n",
    "```\n",
    "\n",
    "### What Gets Traced\n",
    "\n",
    "**Request Details:**\n",
    "- Model/deployment name\n",
    "- Temperature, max_tokens, top_p\n",
    "- Messages (system, user, assistant roles)\n",
    "- Streaming vs non-streaming mode\n",
    "\n",
    "**Response Details:**\n",
    "- Full completion content\n",
    "- Token usage (prompt, completion, total)\n",
    "- Finish reason (stop, length, etc.)\n",
    "- Choice count and index\n",
    "\n",
    "**Performance Metrics:**\n",
    "- End-to-end latency (ms)\n",
    "- Chunk count (for streaming)\n",
    "- Time to first token (streaming)\n",
    "\n",
    "**Context:**\n",
    "- Span IDs (OpenTelemetry format)\n",
    "- Parent-child relationships\n",
    "- Timestamps (ISO 8601)\n",
    "- Status codes (OK, ERROR)\n",
    "\n",
    "### Benefits\n",
    "\n",
    "âœ… **No Cloud Dependencies**: Works offline without Azure Monitor  \n",
    "âœ… **Cost-Free**: No Application Insights charges  \n",
    "âœ… **Fast Queries**: Direct SQL access with Pandas  \n",
    "âœ… **Privacy**: Data never leaves your machine  \n",
    "âœ… **Detailed Debugging**: Full prompt/response capture  \n",
    "âœ… **Performance Analysis**: Track latency trends over time  \n",
    "\n",
    "### Use Cases\n",
    "\n",
    "- **Local Development**: Test and debug without cloud costs\n",
    "- **Performance Optimization**: Identify slow API calls\n",
    "- **Token Usage Tracking**: Monitor and optimize token consumption\n",
    "- **API Testing**: Compare different prompts and parameters\n",
    "- **Debugging**: Reproduce issues with full conversation context\n",
    "- **Cost Estimation**: Calculate API costs before production deployment\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- Azure OpenAI endpoint and API key\n",
    "- Python 3.8+\n",
    "- OpenTelemetry packages (installed automatically)\n",
    "- SQLite (built into Python)\n",
    "- Environment variables configured (see Part 1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af19f0d9",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Part 1: Environment Setup](#part-1-environment-setup)\n",
    "   - 1.1: Install Dependencies\n",
    "   - 1.2: Configure Environment & Imports\n",
    "   - 1.3: Initialize Tracing\n",
    "   - 1.4: Initialize Azure OpenAI Clients\n",
    "2. [Part 2: Synchronous API Calls](#part-2-synchronous-api-calls)\n",
    "3. [Part 3: Asynchronous API Calls](#part-3-asynchronous-api-calls)\n",
    "4. [Part 4: Streaming Responses](#part-4-streaming-responses)\n",
    "5. [Part 5: Async Streaming](#part-5-async-streaming)\n",
    "6. [Part 6: Query and Analyze Traces](#part-6-query-and-analyze-traces)\n",
    "7. [Part 7: Database Management](#part-7-database-management)\n",
    "8. [Summary and Best Practices](#summary-and-best-practices)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284123cf",
   "metadata": {},
   "source": [
    "## Part 1: Environment Setup\n",
    "\n",
    "### 1.1: Install Dependencies\n",
    "\n",
    "Install required packages for local tracing with Azure OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84f1154",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU openai python-dotenv  opentelemetry-sdk opentelemetry-api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c507cff",
   "metadata": {},
   "source": [
    "### 1.2: Configure Environment & Imports\n",
    "\n",
    "Load environment variables and import tracing utilities.\n",
    "\n",
    "**Required Environment Variables:**\n",
    "- `AZURE_OPENAI_ENDPOINT_GPT_4o`: Your Azure OpenAI endpoint\n",
    "- `AZURE_OPENAI_API_KEY_GPT_4o`: Your Azure OpenAI API key\n",
    "\n",
    "**Tracing Utilities:**\n",
    "- `setup_tracing()`: Initialize OpenTelemetry with SQLite exporter\n",
    "- `traced_chat_completion()`: Sync API call wrapper\n",
    "- `traced_chat_completion_async()`: Async API call wrapper\n",
    "- `traced_chat_completion_streaming()`: Sync streaming wrapper\n",
    "- `traced_chat_completion_streaming_async()`: Async streaming wrapper\n",
    "- `flush_traces()`: Force export pending spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03926c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI, AsyncAzureOpenAI\n",
    "\n",
    "# Suppress verbose logging\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"openai\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"opentelemetry\").setLevel(logging.WARNING)\n",
    "\n",
    "# Import tracing utilities\n",
    "from tracing_utils import (\n",
    "    setup_tracing,\n",
    "    traced_chat_completion,\n",
    "    traced_chat_completion_async,\n",
    "    traced_chat_completion_streaming,\n",
    "    traced_chat_completion_streaming_async,\n",
    "    flush_traces\n",
    ")\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "# Verify environment variables\n",
    "required_vars = [\"AZURE_OPENAI_ENDPOINT_GPT_4o\", \"AZURE_OPENAI_API_KEY_GPT_4o\"]\n",
    "missing = [var for var in required_vars if not os.getenv(var)]\n",
    "if missing:\n",
    "    print(f\"âš ï¸  Warning: Missing environment variables: {missing}\")\n",
    "else:\n",
    "    print(\"âœ… Environment variables loaded successfully\")\n",
    "    print(\"âœ… Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dfdd33",
   "metadata": {},
   "source": [
    "### 1.3: Initialize Tracing\n",
    "\n",
    "Setup tracing with SQLite storage and optional console output.\n",
    "\n",
    "**Configuration Options:**\n",
    "- `service_name`: Identifies your application in traces\n",
    "- `enable_console`: Print traces to console (default: False)\n",
    "- `enable_sqlite`: Store traces in SQLite database (default: True)\n",
    "- `sqlite_db_path`: Path to SQLite database file\n",
    "- `use_batch_processor`: Batch spans for better performance (default: True)\n",
    "- `verbose`: Print configuration details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d14f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tracing\n",
    "tracer = setup_tracing(\n",
    "    service_name=\"my-azure-openai-app\",\n",
    "    enable_console=False,  # Set to True to see traces in console\n",
    "    enable_sqlite=True,\n",
    "    sqlite_db_path=\"my_traces.db\",\n",
    "    use_batch_processor=True,  # Set to False for immediate writes\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"âœ… Tracing initialized successfully\")\n",
    "print(\"ðŸ“ Traces will be stored in: my_traces.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18582830",
   "metadata": {},
   "source": [
    "### 1.4: Initialize Azure OpenAI Clients\n",
    "\n",
    "Create synchronous and asynchronous clients for Azure OpenAI API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4505b954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synchronous client\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT_GPT_4o\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY_GPT_4o\"),\n",
    "    api_version=\"2024-02-01\"\n",
    ")\n",
    "\n",
    "# Asynchronous client\n",
    "async_client = AsyncAzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT_GPT_4o\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY_GPT_4o\"),\n",
    "    api_version=\"2024-02-01\"\n",
    ")\n",
    "\n",
    "deployment_name = \"gpt-4o-lei\"\n",
    "\n",
    "print(\"âœ… Azure OpenAI clients initialized\")\n",
    "print(f\"   Deployment: {deployment_name}\")\n",
    "print(f\"   Endpoint: {os.getenv('AZURE_OPENAI_ENDPOINT_GPT_4o')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6bc953",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Synchronous API Calls\n",
    "\n",
    "Use `traced_chat_completion()` to make synchronous API calls with automatic tracing.\n",
    "\n",
    "**What Gets Traced:**\n",
    "- Request parameters (model, temperature, max_tokens)\n",
    "- Full prompt messages (system, user roles)\n",
    "- Completion content\n",
    "- Token usage (prompt, completion, total)\n",
    "- Latency (milliseconds)\n",
    "- Status (success/failure)\n",
    "\n",
    "**Return Values:**\n",
    "- `response`: Standard OpenAI ChatCompletion object\n",
    "- `latency`: End-to-end latency in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f98f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define messages\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What are the benefits of using Azure OpenAI?\"}\n",
    "]\n",
    "\n",
    "# Make traced API call\n",
    "response, latency = traced_chat_completion(\n",
    "    client=client,\n",
    "    tracer=tracer,\n",
    "    messages=messages,\n",
    "    model=deployment_name,\n",
    "    temperature=0.7,\n",
    "    max_tokens=200\n",
    ")\n",
    "\n",
    "print(f\"ðŸ“Š Performance Metrics:\")\n",
    "print(f\"   Latency: {latency*1000:.2f}ms\")\n",
    "print(f\"   Tokens: {response.usage.total_tokens} (prompt: {response.usage.prompt_tokens}, completion: {response.usage.completion_tokens})\")\n",
    "print(f\"   Finish reason: {response.choices[0].finish_reason}\")\n",
    "print(f\"\\nðŸ’¬ Response:\\n{response.choices[0].message.content}\")\n",
    "\n",
    "print(\"\\nâœ… Trace stored in SQLite database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685fdb91",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Asynchronous API Calls\n",
    "\n",
    "Use `traced_chat_completion_async()` for async/await pattern with automatic tracing.\n",
    "\n",
    "**Benefits of Async:**\n",
    "- Non-blocking I/O for concurrent operations\n",
    "- Better throughput for multiple API calls\n",
    "- Ideal for web servers and high-concurrency applications\n",
    "\n",
    "**Usage:**\n",
    "- Requires `await` keyword\n",
    "- Returns same values as sync version\n",
    "- All tracing features work identically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0c9046",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Explain distributed tracing in 2 sentences.\"}\n",
    "]\n",
    "\n",
    "# Make async traced API call\n",
    "response, latency = await traced_chat_completion_async(\n",
    "    client=async_client,\n",
    "    tracer=tracer,\n",
    "    messages=messages,\n",
    "    model=deployment_name,\n",
    "    temperature=0.7,\n",
    "    max_tokens=100\n",
    ")\n",
    "\n",
    "print(f\"ðŸ“Š Performance Metrics:\")\n",
    "print(f\"   Latency: {latency*1000:.2f}ms\")\n",
    "print(f\"   Tokens: {response.usage.total_tokens}\")\n",
    "print(f\"\\nðŸ’¬ Response:\\n{response.choices[0].message.content}\")\n",
    "\n",
    "print(\"\\nâœ… Async trace stored in SQLite database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a6dd78",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Streaming Responses\n",
    "\n",
    "Use `traced_chat_completion_streaming()` for streaming responses with automatic tracing.\n",
    "\n",
    "### Option 1: Collect All Chunks (Recommended for Tracing)\n",
    "\n",
    "The traced wrapper collects all chunks, assembles the complete response, and then returns it. This ensures accurate token counting and complete content capture for the trace.\n",
    "\n",
    "**What Gets Traced:**\n",
    "- Complete assembled content\n",
    "- Total chunk count\n",
    "- End-to-end latency (including all chunks)\n",
    "- All standard request/response attributes\n",
    "\n",
    "**Return Values:**\n",
    "- `content`: Complete assembled response text\n",
    "- `chunks`: Total number of chunks received\n",
    "- `latency`: Time from start to last chunk (seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13734af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is observability?\"}\n",
    "]\n",
    "\n",
    "print(\"ðŸ’¬ Streaming Response:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Use the traced function (collects all chunks, then prints)\n",
    "content, chunks, latency = traced_chat_completion_streaming(\n",
    "    client=client,\n",
    "    tracer=tracer,\n",
    "    messages=messages,\n",
    "    model=deployment_name,\n",
    "    temperature=0.7,\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "print(content)\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(f\"\\nðŸ“Š Streaming Metrics:\")\n",
    "print(f\"   Latency: {latency*1000:.2f}ms\")\n",
    "print(f\"   Chunks received: {chunks}\")\n",
    "print(f\"   Content length: {len(content)} chars\")\n",
    "print(f\"   Avg chunk size: {len(content)/chunks:.1f} chars/chunk\")\n",
    "\n",
    "print(\"\\nâœ… Streaming trace stored in SQLite database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0bfc45",
   "metadata": {},
   "source": [
    "### Option 2: Real-Time Streaming Output\n",
    "\n",
    "For **real-time streaming** (printing each chunk as it arrives), manually iterate over the stream and create a custom span.\n",
    "\n",
    "**Trade-offs:**\n",
    "- âœ… Immediate user feedback (better UX)\n",
    "- âš ï¸ Manual span management required\n",
    "- âš ï¸ Token counts not available until complete\n",
    "- âš ï¸ More complex error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc797a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from opentelemetry.trace import SpanKind, Status, StatusCode\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is observability? Explain in 3-4 sentences.\"}\n",
    "]\n",
    "\n",
    "print(\"ðŸ’¬ Real-Time Streaming Response:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Create a traced span manually\n",
    "with tracer.start_as_current_span(\n",
    "    \"azure_openai_streaming_realtime\",\n",
    "    kind=SpanKind.CLIENT,\n",
    "    attributes={\n",
    "        \"gen_ai.system\": \"azure.openai\",\n",
    "        \"gen_ai.request.model\": deployment_name,\n",
    "        \"gen_ai.operation.name\": \"chat.completions.streaming\",\n",
    "        \"gen_ai.request.streaming\": True,\n",
    "        \"gen_ai.request.temperature\": 0.7,\n",
    "        \"gen_ai.request.max_tokens\": 500,\n",
    "    }\n",
    ") as span:\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        # Add message attributes\n",
    "        for idx, msg in enumerate(messages):\n",
    "            span.set_attribute(f\"gen_ai.prompt.{idx}.role\", msg[\"role\"])\n",
    "            span.set_attribute(f\"gen_ai.prompt.{idx}.content\", msg[\"content\"])\n",
    "\n",
    "        # Make streaming API call\n",
    "        stream = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=messages,\n",
    "            temperature=0.7,\n",
    "            max_tokens=500,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        # Stream and print in real-time\n",
    "        full_content = \"\"\n",
    "        chunk_count = 0\n",
    "\n",
    "        for chunk in stream:\n",
    "            chunk_count += 1\n",
    "            if chunk.choices and chunk.choices[0].delta.content:\n",
    "                content = chunk.choices[0].delta.content\n",
    "                full_content += content\n",
    "                # Print each chunk immediately (real-time streaming!)\n",
    "                print(content, end='', flush=True)\n",
    "\n",
    "        print()  # New line after streaming completes\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "        # Calculate metrics\n",
    "        latency = time.time() - start_time\n",
    "\n",
    "        # Add final attributes to span\n",
    "        span.set_attribute(\"gen_ai.completion.0.content\", full_content)\n",
    "        span.set_attribute(\"gen_ai.response.chunk_count\", chunk_count)\n",
    "        span.set_attribute(\"gen_ai.response.latency_ms\", latency * 1000)\n",
    "        span.set_status(Status(StatusCode.OK))\n",
    "\n",
    "        print(f\"\\nðŸ“Š Real-Time Streaming Metrics:\")\n",
    "        print(f\"   Latency: {latency*1000:.2f}ms\")\n",
    "        print(f\"   Chunks received: {chunk_count}\")\n",
    "        print(f\"   Total length: {len(full_content)} chars\")\n",
    "\n",
    "        print(\"\\nâœ… Real-time streaming trace stored in SQLite database\")\n",
    "\n",
    "    except Exception as e:\n",
    "        span.set_status(Status(StatusCode.ERROR, str(e)))\n",
    "        span.record_exception(e)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6174e7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Async Streaming\n",
    "\n",
    "Combine asynchronous execution with streaming responses for maximum performance.\n",
    "\n",
    "### Option 1: Async Wrapper (Recommended)\n",
    "\n",
    "Use `traced_chat_completion_streaming_async()` for automatic tracing with async/await pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aefebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is telemetry data?\"}\n",
    "]\n",
    "\n",
    "# Use the traced async streaming function\n",
    "content, chunks, latency = await traced_chat_completion_streaming_async(\n",
    "    client=async_client,\n",
    "    tracer=tracer,\n",
    "    messages=messages,\n",
    "    model=deployment_name,\n",
    "    temperature=0.7,\n",
    "    max_tokens=150\n",
    ")\n",
    "\n",
    "print(f\"ðŸ“Š Async Streaming Metrics:\")\n",
    "print(f\"   Latency: {latency*1000:.2f}ms\")\n",
    "print(f\"   Chunks: {chunks}\")\n",
    "print(f\"   Content length: {len(content)} chars\")\n",
    "print(f\"   Avg chunk size: {len(content)/chunks:.1f} chars/chunk\")\n",
    "\n",
    "print(f\"\\nðŸ’¬ Response:\\n{content}\")\n",
    "\n",
    "print(\"\\nâœ… Async streaming trace stored in SQLite database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ac9ddc",
   "metadata": {},
   "source": [
    "### Option 2: Async Real-Time Streaming\n",
    "\n",
    "For real-time output with async client, manually manage the async stream and span."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed28efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is distributed tracing? Explain in 3 sentences.\"}\n",
    "]\n",
    "\n",
    "print(\"ðŸ’¬ Real-Time Async Streaming Response:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Create a traced span manually\n",
    "with tracer.start_as_current_span(\n",
    "    \"azure_openai_async_streaming_realtime\",\n",
    "    kind=SpanKind.CLIENT,\n",
    "    attributes={\n",
    "        \"gen_ai.system\": \"azure.openai\",\n",
    "        \"gen_ai.request.model\": deployment_name,\n",
    "        \"gen_ai.operation.name\": \"chat.completions.async_streaming\",\n",
    "        \"gen_ai.request.streaming\": True,\n",
    "        \"gen_ai.request.temperature\": 0.7,\n",
    "        \"gen_ai.request.max_tokens\": 500,\n",
    "    }\n",
    ") as span:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Add message attributes\n",
    "        for idx, msg in enumerate(messages):\n",
    "            span.set_attribute(f\"gen_ai.prompt.{idx}.role\", msg[\"role\"])\n",
    "            span.set_attribute(f\"gen_ai.prompt.{idx}.content\", msg[\"content\"])\n",
    "        \n",
    "        # Make async streaming API call\n",
    "        stream = await async_client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=messages,\n",
    "            temperature=0.7,\n",
    "            max_tokens=500,\n",
    "            stream=True\n",
    "        )\n",
    "        \n",
    "        # Stream and print in real-time\n",
    "        full_content = \"\"\n",
    "        chunk_count = 0\n",
    "        \n",
    "        async for chunk in stream:\n",
    "            chunk_count += 1\n",
    "            if chunk.choices and chunk.choices[0].delta.content:\n",
    "                content = chunk.choices[0].delta.content\n",
    "                full_content += content\n",
    "                # Print each chunk immediately (real-time streaming!)\n",
    "                print(content, end='', flush=True)\n",
    "        \n",
    "        print()  # New line after streaming completes\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        latency = time.time() - start_time\n",
    "        \n",
    "        # Add final attributes to span\n",
    "        span.set_attribute(\"gen_ai.completion.0.content\", full_content)\n",
    "        span.set_attribute(\"gen_ai.response.chunk_count\", chunk_count)\n",
    "        span.set_attribute(\"gen_ai.response.latency_ms\", latency * 1000)\n",
    "        span.set_status(Status(StatusCode.OK))\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Metrics:\")\n",
    "        print(f\"  - Latency: {latency*1000:.2f}ms\")\n",
    "        print(f\"  - Chunks received: {chunk_count}\")\n",
    "        print(f\"  - Total length: {len(full_content)} chars\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        span.set_status(Status(StatusCode.ERROR, str(e)))\n",
    "        span.record_exception(e)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b32664f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Query and Analyze Traces\n",
    "\n",
    "Query the SQLite database to view and analyze stored traces using SQL and Pandas.\n",
    "\n",
    "### Flush Pending Traces\n",
    "\n",
    "Force flush all pending traces to database (important with BatchSpanProcessor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d748d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flush all pending traces\n",
    "flush_traces(timeout=10)\n",
    "print(\"âœ… All pending traces flushed to database\")\n",
    "print(\"ðŸ“Š Ready for querying and analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ced5c74",
   "metadata": {},
   "source": [
    "### Trace Summary\n",
    "\n",
    "Query the database for an overview of all captured traces.\n",
    "\n",
    "**Queries Include:**\n",
    "- Total span count\n",
    "- Latest 10 traces with timestamps\n",
    "- Performance statistics by operation type\n",
    "- Streaming vs non-streaming comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ce921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "def query_traces(db_path=\"my_traces.db\"):\n",
    "    \"\"\"Query and display trace data from SQLite\"\"\"\n",
    "    \n",
    "    conn = sqlite3.connect(db_path)\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ðŸ“Š TRACE SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Get total count\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM spans\")\n",
    "    total_spans = cursor.fetchone()[0]\n",
    "    print(f\"\\nðŸ“ˆ Total spans stored: {total_spans}\")\n",
    "    \n",
    "    # Get latest spans\n",
    "    print(\"\\nðŸ• Latest 10 Traces:\")\n",
    "    df_spans = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            id,\n",
    "            name,\n",
    "            ROUND(duration_ms, 2) as duration_ms,\n",
    "            status_code,\n",
    "            datetime(created_at) as created_at\n",
    "        FROM spans \n",
    "        ORDER BY created_at DESC \n",
    "        LIMIT 10\n",
    "    \"\"\", conn)\n",
    "    print(df_spans.to_string(index=False))\n",
    "    \n",
    "    # Get performance stats\n",
    "    print(\"\\nâš¡ Performance Statistics:\")\n",
    "    df_stats = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            name,\n",
    "            COUNT(*) as count,\n",
    "            ROUND(AVG(duration_ms), 2) as avg_duration_ms,\n",
    "            ROUND(MIN(duration_ms), 2) as min_duration_ms,\n",
    "            ROUND(MAX(duration_ms), 2) as max_duration_ms\n",
    "        FROM spans \n",
    "        GROUP BY name\n",
    "    \"\"\", conn)\n",
    "    print(df_stats.to_string(index=False))\n",
    "    \n",
    "    # Get streaming vs non-streaming stats\n",
    "    print(\"\\nðŸŒŠ Streaming vs Non-Streaming:\")\n",
    "    df_streaming = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            CASE \n",
    "                WHEN sa.value = 'True' THEN 'Streaming'\n",
    "                ELSE 'Non-Streaming'\n",
    "            END as mode,\n",
    "            COUNT(DISTINCT s.id) as count,\n",
    "            ROUND(AVG(s.duration_ms), 2) as avg_duration_ms\n",
    "        FROM spans s\n",
    "        LEFT JOIN span_attributes sa ON s.id = sa.span_id \n",
    "            AND sa.key = 'gen_ai.request.streaming'\n",
    "        GROUP BY mode\n",
    "    \"\"\", conn)\n",
    "    print(df_streaming.to_string(index=False))\n",
    "    \n",
    "    conn.close()\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Query the database\n",
    "query_traces()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b9b74d",
   "metadata": {},
   "source": [
    "### Latest Span Details\n",
    "\n",
    "View complete details of the most recent trace, including all attributes and metadata.\n",
    "\n",
    "**Includes:**\n",
    "- Span metadata (ID, name, duration, status)\n",
    "- All attributes (prompts, completions, tokens, etc.)\n",
    "- Timestamps and parent relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150562ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_latest_span(db_path=\"my_traces.db\"):\n",
    "    \"\"\"View all details of the latest span\"\"\"\n",
    "    \n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ðŸ” LATEST SPAN DETAILS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    cursor.execute(\"SELECT id FROM spans ORDER BY created_at DESC LIMIT 1\")\n",
    "    latest_span_id = cursor.fetchone()\n",
    "    \n",
    "    if latest_span_id:\n",
    "        span_id = latest_span_id[0]\n",
    "        \n",
    "        # Get span details\n",
    "        df_span = pd.read_sql_query(f\"\"\"\n",
    "            SELECT * FROM spans WHERE id = {span_id}\n",
    "        \"\"\", conn)\n",
    "        \n",
    "        print(\"\\nðŸ“‹ Span Information:\")\n",
    "        for col in df_span.columns:\n",
    "            value = df_span[col].values[0]\n",
    "            print(f\"  {col:20s}: {value}\")\n",
    "        \n",
    "        # Get attributes\n",
    "        df_attrs = pd.read_sql_query(f\"\"\"\n",
    "            SELECT key, value FROM span_attributes \n",
    "            WHERE span_id = {span_id}\n",
    "            ORDER BY key\n",
    "        \"\"\", conn)\n",
    "        \n",
    "        print(f\"\\nðŸ“‹ Attributes ({len(df_attrs)} total):\")\n",
    "        for _, row in df_attrs.iterrows():\n",
    "            key = row['key']\n",
    "            value = row['value']\n",
    "            # Show full value without truncation\n",
    "            print(f\"  {key}\")\n",
    "            print(f\"    â†’ {value}\")\n",
    "    else:\n",
    "        print(\"\\nâŒ No spans found in database\")\n",
    "    \n",
    "    conn.close()\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# View latest span\n",
    "view_latest_span()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065edf5a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Database Management\n",
    "\n",
    "Understanding the SQLite schema, foreign key relationships, and safe data management practices.\n",
    "\n",
    "### Database Schema\n",
    "\n",
    "Explore the relationship between `spans` and `span_attributes` tables and foreign key behavior.\n",
    "\n",
    "**Schema Overview:**\n",
    "- `spans`: Main table with span metadata\n",
    "- `span_attributes`: Key-value attributes for each span\n",
    "- Foreign key: `span_attributes.span_id` â†’ `spans.id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_foreign_key_behavior(db_path=\"my_traces.db\"):\n",
    "    \"\"\"Demonstrate what happens with foreign keys when deleting spans\"\"\"\n",
    "    \n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ðŸ” FOREIGN KEY RELATIONSHIP DEMO\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Show current foreign key setting\n",
    "    cursor.execute(\"PRAGMA foreign_keys\")\n",
    "    fk_status = cursor.fetchone()[0]\n",
    "    print(f\"\\nâš™ï¸  Foreign Keys Enabled: {bool(fk_status)}\")\n",
    "    \n",
    "    # Show the schema\n",
    "    print(\"\\nðŸ“‹ Table Relationships:\")\n",
    "    print(\"\"\"\n",
    "    spans table:\n",
    "    â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚ id â”‚ span_id (hex)        â”‚ name        â”‚  â† PRIMARY KEY\n",
    "    â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "             â†‘\n",
    "             â”‚ FOREIGN KEY\n",
    "             â”‚\n",
    "    span_attributes table:\n",
    "    â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚ id â”‚ span_id â”‚ key          â”‚ value   â”‚  â† span_id references spans.id\n",
    "    â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "    \"\"\")\n",
    "    \n",
    "    # Count current spans and attributes\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM spans\")\n",
    "    span_count = cursor.fetchone()[0]\n",
    "    \n",
    "    cursor.execute(\"SELECT COUNT(*) FROM span_attributes\")\n",
    "    attr_count = cursor.fetchone()[0]\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Current Data:\")\n",
    "    print(f\"  - Total spans: {span_count}\")\n",
    "    print(f\"  - Total attributes: {attr_count}\")\n",
    "    \n",
    "    if span_count > 0:\n",
    "        # Show a sample span with its attributes\n",
    "        cursor.execute(\"SELECT id, span_id, name FROM spans LIMIT 1\")\n",
    "        sample_span = cursor.fetchone()\n",
    "        span_db_id, span_hex_id, span_name = sample_span\n",
    "        \n",
    "        print(f\"\\nðŸ“Œ Sample Span:\")\n",
    "        print(f\"  - Database ID (spans.id): {span_db_id}\")\n",
    "        print(f\"  - OpenTelemetry ID (spans.span_id): {span_hex_id}\")\n",
    "        print(f\"  - Name: {span_name}\")\n",
    "        \n",
    "        cursor.execute(f\"SELECT COUNT(*) FROM span_attributes WHERE span_id = {span_db_id}\")\n",
    "        attr_count_for_span = cursor.fetchone()[0]\n",
    "        print(f\"  - Attributes: {attr_count_for_span}\")\n",
    "        \n",
    "        print(f\"\\nâš ï¸  What happens if you delete spans.id={span_db_id}?\")\n",
    "        print(f\"\"\"\n",
    "        Current behavior (NO CASCADE):\n",
    "        âŒ SQLite will REJECT the delete operation\n",
    "        âŒ Error: \"FOREIGN KEY constraint failed\"\n",
    "        âœ… Data integrity is protected\n",
    "        âœ… No orphaned attributes\n",
    "        \n",
    "        To delete a span, you must:\n",
    "        1. First delete all its attributes manually, OR\n",
    "        2. Enable CASCADE DELETE in the schema\n",
    "        \"\"\")\n",
    "    \n",
    "    conn.close()\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Run the demo\n",
    "demonstrate_foreign_key_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6469030",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary and Best Practices\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Local Tracing**: SQLite-based tracing for offline development and testing\n",
    "2. **Zero Cloud Costs**: No Application Insights charges during development\n",
    "3. **Complete Privacy**: All trace data stays on your local machine\n",
    "4. **Fast Queries**: Direct SQL access with Pandas integration\n",
    "5. **Flexible Wrappers**: Support for sync, async, streaming, and async streaming\n",
    "\n",
    "### What Gets Traced\n",
    "\n",
    "**Request Details:**\n",
    "- Model/deployment name\n",
    "- Temperature, max_tokens, top_p\n",
    "- Full message history (system, user, assistant)\n",
    "- Streaming vs non-streaming mode\n",
    "\n",
    "**Response Details:**\n",
    "- Complete content (prompts and completions)\n",
    "- Token usage (prompt, completion, total)\n",
    "- Finish reason (stop, length, content_filter)\n",
    "- Choice count and index\n",
    "\n",
    "**Performance Metrics:**\n",
    "- End-to-end latency (milliseconds)\n",
    "- Chunk count (streaming)\n",
    "- Time to first token (streaming)\n",
    "- Average chunk size\n",
    "\n",
    "**Context & Metadata:**\n",
    "- Span IDs (OpenTelemetry format)\n",
    "- Parent-child relationships\n",
    "- Timestamps (ISO 8601)\n",
    "- Status codes (OK, ERROR)\n",
    "- Exception details (if errors occur)\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "#### 1. Tracing Configuration\n",
    "- âœ… Use BatchSpanProcessor for better performance (default)\n",
    "- âœ… Call `flush_traces()` before script/notebook ends\n",
    "- âœ… Disable console output in production (`enable_console=False`)\n",
    "- âœ… Use descriptive service names for identification\n",
    "- âœ… Suppress verbose logging for cleaner output\n",
    "\n",
    "#### 2. API Call Patterns\n",
    "- âœ… Use traced wrappers for automatic instrumentation\n",
    "- âœ… Prefer async for concurrent operations\n",
    "- âœ… Use streaming for long responses (better UX)\n",
    "- âœ… Collect chunks for accurate tracing (Option 1)\n",
    "- âœ… Use real-time streaming only when needed (Option 2)\n",
    "\n",
    "#### 3. Database Management\n",
    "- âœ… Enable CASCADE DELETE for easier cleanup\n",
    "- âœ… Always set `PRAGMA foreign_keys = ON` in SQLite\n",
    "- âœ… Implement data retention policies (delete old traces)\n",
    "- âœ… Back up database before major changes\n",
    "- âœ… Monitor database size for long-running applications\n",
    "\n",
    "#### 4. Performance Analysis\n",
    "- âœ… Query by operation type to identify patterns\n",
    "- âœ… Track latency percentiles (P50, P95, P99)\n",
    "- âœ… Monitor token usage trends over time\n",
    "- âœ… Compare streaming vs non-streaming performance\n",
    "- âœ… Identify outliers and investigate anomalies\n",
    "\n",
    "#### 5. Debugging Workflows\n",
    "- âœ… Use span IDs to trace specific requests\n",
    "- âœ… Review full prompt/completion content\n",
    "- âœ… Check token usage for optimization opportunities\n",
    "- âœ… Analyze error traces for exception patterns\n",
    "- âœ… Compare before/after traces for A/B testing\n",
    "\n",
    "#### 6. Privacy & Security\n",
    "- âœ… Keep database files secure (contains prompts/responses)\n",
    "- âœ… Add database to `.gitignore` (avoid committing traces)\n",
    "- âœ… Consider encrypting database for sensitive data\n",
    "- âœ… Implement data retention policies (auto-delete old data)\n",
    "- âœ… Review compliance requirements (GDPR, HIPAA, etc.)\n",
    "\n",
    "### Database Schema\n",
    "\n",
    "**spans table:**\n",
    "```sql\n",
    "CREATE TABLE spans (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    span_id TEXT NOT NULL,           -- OpenTelemetry span ID (hex)\n",
    "    trace_id TEXT NOT NULL,          -- OpenTelemetry trace ID (hex)\n",
    "    parent_span_id TEXT,             -- Parent span ID (for hierarchy)\n",
    "    name TEXT NOT NULL,              -- Operation name\n",
    "    kind INTEGER NOT NULL,           -- Span kind (CLIENT, SERVER, etc.)\n",
    "    start_time INTEGER NOT NULL,     -- Start timestamp (nanoseconds)\n",
    "    end_time INTEGER NOT NULL,       -- End timestamp (nanoseconds)\n",
    "    duration_ms REAL NOT NULL,       -- Duration in milliseconds\n",
    "    status_code INTEGER NOT NULL,    -- Status (OK=0, ERROR=1)\n",
    "    status_message TEXT,             -- Error message (if any)\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    ")\n",
    "```\n",
    "\n",
    "**span_attributes table:**\n",
    "```sql\n",
    "CREATE TABLE span_attributes (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    span_id INTEGER NOT NULL,\n",
    "    key TEXT NOT NULL,\n",
    "    value TEXT,\n",
    "    FOREIGN KEY (span_id) REFERENCES spans(id) ON DELETE CASCADE\n",
    ")\n",
    "```\n",
    "\n",
    "### Common SQL Queries\n",
    "\n",
    "**Find slow API calls:**\n",
    "```sql\n",
    "SELECT name, duration_ms, datetime(created_at) as time\n",
    "FROM spans \n",
    "WHERE duration_ms > 2000  -- Slower than 2 seconds\n",
    "ORDER BY duration_ms DESC;\n",
    "```\n",
    "\n",
    "**Token usage by day:**\n",
    "```sql\n",
    "SELECT \n",
    "    DATE(created_at) as date,\n",
    "    SUM(CAST(value AS INTEGER)) as total_tokens\n",
    "FROM spans s\n",
    "JOIN span_attributes sa ON s.id = sa.span_id\n",
    "WHERE sa.key = 'gen_ai.usage.total_tokens'\n",
    "GROUP BY DATE(created_at)\n",
    "ORDER BY date DESC;\n",
    "```\n",
    "\n",
    "**Error analysis:**\n",
    "```sql\n",
    "SELECT \n",
    "    name,\n",
    "    status_message,\n",
    "    datetime(created_at) as time\n",
    "FROM spans\n",
    "WHERE status_code = 2  -- ERROR status\n",
    "ORDER BY created_at DESC;\n",
    "```\n",
    "\n",
    "**Average latency by operation:**\n",
    "```sql\n",
    "SELECT \n",
    "    name,\n",
    "    COUNT(*) as count,\n",
    "    ROUND(AVG(duration_ms), 2) as avg_ms,\n",
    "    ROUND(MIN(duration_ms), 2) as min_ms,\n",
    "    ROUND(MAX(duration_ms), 2) as max_ms\n",
    "FROM spans\n",
    "GROUP BY name\n",
    "ORDER BY avg_ms DESC;\n",
    "```\n",
    "\n",
    "### Migration to Cloud Tracing\n",
    "\n",
    "When ready for production, migrate to Azure Monitor (Application Insights):\n",
    "\n",
    "1. **Keep Local Tracing for Development:**\n",
    "   - Continue using SQLite for testing\n",
    "   - Use for cost-free experimentation\n",
    "   - Validate changes before deployment\n",
    "\n",
    "2. **Add Azure Monitor for Production:**\n",
    "   - See `01_azure_foundry_tracing.ipynb` for setup\n",
    "   - Automatic export to Application Insights\n",
    "   - Built-in dashboards and alerting\n",
    "   - KQL queries for advanced analysis\n",
    "\n",
    "3. **Hybrid Approach:**\n",
    "   - Use both local and cloud tracing\n",
    "   - Local for development/debugging\n",
    "   - Cloud for production monitoring\n",
    "   - Compare results between environments\n",
    "\n",
    "### Troubleshooting\n",
    "\n",
    "| Issue | Solution |\n",
    "|-------|----------|\n",
    "| No traces in database | Call `flush_traces()` before querying |\n",
    "| Foreign key errors | Run `PRAGMA foreign_keys = ON` in SQLite |\n",
    "| Large database size | Implement data retention (delete old traces) |\n",
    "| Slow queries | Add indexes on frequently queried columns |\n",
    "| Missing attributes | Check traced wrapper is used correctly |\n",
    "| Incomplete content | Use Option 1 (collect chunks) for streaming |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Customize Tracing**: Modify `tracing_utils.py` for your needs\n",
    "2. **Add Indexes**: Optimize database for your query patterns\n",
    "3. **Implement Retention**: Auto-delete old traces (e.g., > 30 days)\n",
    "4. **Build Dashboards**: Create Jupyter dashboards with plotly/matplotlib\n",
    "5. **Export Data**: Export to CSV/JSON for external analysis\n",
    "6. **Migrate to Cloud**: Set up Azure Monitor for production workloads\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [OpenTelemetry Python SDK](https://opentelemetry.io/docs/instrumentation/python/)\n",
    "- [OpenTelemetry Semantic Conventions](https://opentelemetry.io/docs/specs/semconv/)\n",
    "- [SQLite Documentation](https://www.sqlite.org/docs.html)\n",
    "- [Pandas SQL Guide](https://pandas.pydata.org/docs/reference/api/pandas.read_sql_query.html)\n",
    "- [Azure Monitor OpenTelemetry](https://learn.microsoft.com/azure/azure-monitor/app/opentelemetry-enable)\n",
    "\n",
    "### Related Notebooks\n",
    "\n",
    "- `01_azure_foundry_tracing.ipynb`: Cloud-based tracing with Application Insights\n",
    "- `../01_agent/`: Azure AI agent examples\n",
    "- `../05_evaluation/`: Agent evaluation and metrics\n",
    "- `../02_governance/`: Compliance and governance patterns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
