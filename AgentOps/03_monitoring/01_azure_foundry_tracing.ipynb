{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b48b59a",
   "metadata": {},
   "source": [
    "# Azure AI Foundry Agent Tracing\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook demonstrates **Azure AI Foundry's built-in automatic tracing** for AI agents using OpenTelemetry and Azure Monitor. Tracing provides complete observability into agent behavior, performance, and interactions with minimal code changes.\n",
    "\n",
    "### What is Agent Tracing?\n",
    "\n",
    "Agent tracing captures detailed telemetry about:\n",
    "- **Agent Operations**: Creation, configuration, execution lifecycle\n",
    "- **LLM Interactions**: Model requests, responses, token usage, latency\n",
    "- **Tool/Function Calls**: Arguments, results, execution time\n",
    "- **Message Flow**: User queries, assistant responses, conversation context\n",
    "- **Performance Metrics**: Latency, success rates, error tracking\n",
    "- **Cost Analysis**: Token consumption and API usage patterns\n",
    "\n",
    "All traces automatically flow to **Application Insights** for centralized monitoring and analysis.\n",
    "\n",
    "### Key Features\n",
    "\n",
    "**Zero Manual Instrumentation:**\n",
    "- Azure AI Foundry SDK automatically instruments all agent operations\n",
    "- No need to manually wrap code with telemetry spans\n",
    "- Built-in integration with OpenTelemetry standards\n",
    "\n",
    "**Automatic Export:**\n",
    "- Traces flow directly to Azure Monitor (Application Insights)\n",
    "- Real-time visibility into agent performance\n",
    "- Distributed tracing across services\n",
    "\n",
    "**Content Recording (Opt-in):**\n",
    "- Capture full prompts and completions for debugging\n",
    "- PII-aware configuration options\n",
    "- Control via environment variables\n",
    "\n",
    "**Rich Analytics:**\n",
    "- Query traces with KQL (Kusto Query Language)\n",
    "- Pre-built dashboards in Azure AI Foundry Portal\n",
    "- Custom visualizations in Application Insights\n",
    "\n",
    "**Production-Ready:**\n",
    "- Built-in retry and error handling\n",
    "- Buffered export with automatic batching\n",
    "- Minimal performance overhead\n",
    "\n",
    "### Tracing Workflow\n",
    "\n",
    "```\n",
    "1. Configure OpenTelemetry + Azure Monitor\n",
    "   â†“\n",
    "2. Run Agent Operations (automatically traced)\n",
    "   â†“\n",
    "3. Traces Export to Application Insights\n",
    "   â†“\n",
    "4. View in Azure AI Foundry Portal / App Insights\n",
    "   â†“\n",
    "5. Query with KQL for Analysis\n",
    "   â†“\n",
    "6. Set Up Alerts & Dashboards\n",
    "```\n",
    "\n",
    "### What Gets Automatically Traced\n",
    "\n",
    "**Agent SDK Operations:**\n",
    "- `agents.create_agent()` - Agent creation with model config\n",
    "- `threads.create()` - Conversation thread initialization\n",
    "- `messages.create()` - User/assistant message creation\n",
    "- `runs.create_and_process()` - Complete agent execution\n",
    "- `runs.submit_tool_outputs()` - Function result submission\n",
    "- `messages.list()` - Message retrieval\n",
    "\n",
    "**LLM Details:**\n",
    "- Model name and version\n",
    "- Prompt tokens, completion tokens, total tokens\n",
    "- Request/response latency\n",
    "- Temperature, max_tokens, and other parameters\n",
    "- Success/failure status codes\n",
    "\n",
    "**Tool/Function Calls:**\n",
    "- Function name and description\n",
    "- Input arguments (JSON)\n",
    "- Return values\n",
    "- Execution duration\n",
    "- Error messages if failures occur\n",
    "\n",
    "### Benefits\n",
    "\n",
    "âœ… **Complete Visibility**: Every agent operation is traced end-to-end  \n",
    "âœ… **Performance Monitoring**: Identify slow operations and bottlenecks  \n",
    "âœ… **Error Tracking**: Automatic exception capture with stack traces  \n",
    "âœ… **Cost Management**: Track token usage and API costs  \n",
    "âœ… **Debugging**: Reproduce issues with full conversation context  \n",
    "âœ… **Compliance**: Audit trail for all agent interactions  \n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- Azure AI Foundry project with Application Insights enabled\n",
    "- Azure OpenAI deployment (GPT-4, GPT-4o, or similar)\n",
    "- Azure credentials configured (`az login`)\n",
    "- Environment variables configured (see Part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423f7d0e",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Part 1: Environment Setup](#part-1-environment-setup)\n",
    "   - 1.1: Install Dependencies\n",
    "   - 1.2: Configure Environment Variables\n",
    "   - 1.3: Initialize Tracing\n",
    "2. [Part 2: Trace Agent Creation](#part-2-trace-agent-creation)\n",
    "3. [Part 3: Trace Agent Execution](#part-3-trace-agent-execution)\n",
    "4. [Part 4: Trace Function Calling](#part-4-trace-function-calling)\n",
    "5. [Part 5: View Traces in Azure Portal](#part-5-view-traces-in-azure-portal)\n",
    "6. [Part 6: Monitoring Best Practices](#part-6-monitoring-best-practices)\n",
    "7. [Summary and Best Practices](#summary-and-best-practices)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1130d93",
   "metadata": {},
   "source": [
    "## Part 1: Environment Setup\n",
    "\n",
    "### 1.1: Install Dependencies\n",
    "\n",
    "Install required packages for Azure AI Foundry tracing with OpenTelemetry and Azure Monitor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac5000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU --upgrade pip\n",
    "%pip install -qU pandas\n",
    "%pip install -qU azure-identity\n",
    "%pip install -qU azure-ai-projects\n",
    "%pip install -qU azure-monitor-opentelemetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a70fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "new_path_entry = \"/opt/homebrew/bin\"  # Replace with the directory you want to add\n",
    "current_path = os.environ.get('PATH', '')\n",
    "\n",
    "if new_path_entry not in current_path.split(os.pathsep):\n",
    "    os.environ['PATH'] = new_path_entry + os.pathsep + current_path\n",
    "    print(f\"Updated PATH for this session: {os.environ['PATH']}\")\n",
    "else:\n",
    "    print(f\"PATH already contains {new_path_entry}: {current_path}\")\n",
    "\n",
    "# You can then verify with shutil.which again\n",
    "print(f\"Location of 'az' found by kernel now: {shutil.which('az')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd87264",
   "metadata": {},
   "source": [
    "### 1.2: Configure Environment Variables\n",
    "\n",
    "Load environment configuration and enable content recording for detailed tracing.\n",
    "\n",
    "**Required Environment Variables:**\n",
    "- `AZURE_AI_PROJECT_ENDPOINT`: Your Azure AI Foundry project endpoint\n",
    "- `AZURE_OPENAI_ENDPOINT_GPT_4o`: Azure OpenAI endpoint\n",
    "\n",
    "**Content Recording:**\n",
    "- Set `AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED=true` to capture prompts/responses\n",
    "- âš ï¸ May contain personal data - review your compliance requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c462a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv \n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "# Add agent utilities to path\n",
    "current_dir = Path.cwd()\n",
    "sys.path.insert(0, str(current_dir.parent / '01_agent'))\n",
    "\n",
    "# Enable content recording for tracing (may contain personal data)\n",
    "os.environ[\"AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED\"] = \"true\"\n",
    "\n",
    "# Verify environment variables\n",
    "required_vars = [\"AZURE_AI_PROJECT_ENDPOINT\", \"AZURE_OPENAI_ENDPOINT_GPT_4o\"]\n",
    "missing = [var for var in required_vars if not os.getenv(var)]\n",
    "if missing:\n",
    "    print(f\"âš ï¸  Warning: Missing environment variables: {missing}\")\n",
    "else:\n",
    "    print(\"âœ… Environment variables loaded successfully\")\n",
    "    print(\"âœ… Content recording enabled for tracing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c9320b",
   "metadata": {},
   "source": [
    "### 1.3: Initialize Tracing\n",
    "\n",
    "Configure Azure Monitor with Application Insights connection string and suppress verbose logging.\n",
    "\n",
    "**Tracing Setup:**\n",
    "1. Initialize Azure AI Project Client\n",
    "2. Retrieve Application Insights connection string\n",
    "3. Configure Azure Monitor OpenTelemetry exporter\n",
    "4. Get tracer for custom spans (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83371671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "from opentelemetry import trace\n",
    "from opentelemetry.trace import SpanKind, Status, StatusCode\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# Suppress verbose logging\n",
    "logging.getLogger(\"azure.core.pipeline.policies.http_logging_policy\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"azure.identity\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"opentelemetry\").setLevel(logging.WARNING)\n",
    "\n",
    "# Initialize Azure AI Project Client\n",
    "project_client = AIProjectClient(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    endpoint=os.getenv(\"AZURE_AI_PROJECT_ENDPOINT\")\n",
    ")\n",
    "\n",
    "print(\"âœ… Azure AI Foundry client initialized\")\n",
    "\n",
    "# Configure Azure Monitor with Application Insights\n",
    "try:\n",
    "    connection_string = project_client.telemetry.get_application_insights_connection_string()\n",
    "    configure_azure_monitor(connection_string=connection_string)\n",
    "    print(\"âœ… Azure Monitor tracing configured\")\n",
    "    print(f\"   Connection string: {connection_string[:50]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Could not configure Azure Monitor: {e}\")\n",
    "    print(\"   Traces will only be available locally\")\n",
    "\n",
    "# Get tracer for custom spans\n",
    "tracer = trace.get_tracer(__name__)\n",
    "\n",
    "print(\"âœ… OpenTelemetry tracing ready\")\n",
    "print(\"\\nðŸ“Š Traces will be sent to:\")\n",
    "print(\"   - Azure Monitor (Application Insights)\")\n",
    "print(\"   - View in Azure AI Foundry Portal -> Tracing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97ceea6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Trace Agent Creation\n",
    "\n",
    "Capture telemetry when creating a new agent, including model selection, instructions, and configuration.\n",
    "\n",
    "**What Gets Traced Automatically:**\n",
    "- Agent creation API call (`agents.create_agent()`)\n",
    "- Model configuration (name, deployment)\n",
    "- Agent metadata (name, instructions, tools)\n",
    "- Creation latency and success status\n",
    "\n",
    "**Custom Span Attributes:**\n",
    "- Add workflow-level context with custom spans\n",
    "- Track business logic and high-level operations\n",
    "- Correlate multiple Azure AI operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46016697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traced_create_agent(project_client: AIProjectClient, model: str, name: str, instructions: str):\n",
    "    \"\"\"Create an agent with Azure AI Foundry built-in tracing\"\"\"\n",
    "    \n",
    "    with tracer.start_as_current_span(\n",
    "        \"create_agent_workflow\",\n",
    "        kind=SpanKind.CLIENT,\n",
    "        attributes={\n",
    "            \"agent.name\": name,\n",
    "            \"agent.model\": model,\n",
    "            \"workflow.type\": \"agent_creation\"\n",
    "        }\n",
    "    ) as span:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # Azure AI Foundry automatically traces this call\n",
    "            agent = project_client.agents.create_agent(\n",
    "                model=model,\n",
    "                name=name,\n",
    "                instructions=instructions\n",
    "            )\n",
    "            \n",
    "            latency = time.time() - start_time\n",
    "            \n",
    "            # Add workflow-level attributes\n",
    "            span.set_attribute(\"agent.id\", agent.id)\n",
    "            span.set_attribute(\"workflow.latency_ms\", latency * 1000)\n",
    "            span.set_attribute(\"workflow.success\", True)\n",
    "            span.set_status(Status(StatusCode.OK))\n",
    "            \n",
    "            print(f\"âœ… Agent created: {agent.id}\")\n",
    "            print(f\"   Name: {name}\")\n",
    "            print(f\"   Model: {model}\")\n",
    "            print(f\"   Latency: {latency*1000:.2f}ms\")\n",
    "            \n",
    "            return agent\n",
    "            \n",
    "        except Exception as e:\n",
    "            span.set_status(Status(StatusCode.ERROR, str(e)))\n",
    "            span.record_exception(e)\n",
    "            print(f\"âŒ Error creating agent: {e}\")\n",
    "            raise\n",
    "\n",
    "# Example: Create a traced agent\n",
    "test_agent = traced_create_agent(\n",
    "    project_client=project_client,\n",
    "    model=\"gpt-4o\",\n",
    "    name=\"TracedTestAgent\",\n",
    "    instructions=\"You are a helpful assistant for testing tracing capabilities.\"\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ’¡ View traces in Azure AI Foundry Portal:\")\n",
    "print(\"   Project â†’ Tracing â†’ Filter by agent ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6901de9b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Trace Agent Execution\n",
    "\n",
    "Monitor complete agent runs including thread creation, message processing, and response generation.\n",
    "\n",
    "**Automatically Traced Operations:**\n",
    "- Thread creation (`threads.create()`)\n",
    "- Message creation (`messages.create()`)\n",
    "- Agent run execution (`runs.create_and_process()`)\n",
    "- Message retrieval (`messages.list()`)\n",
    "- Token usage and latency for each step\n",
    "\n",
    "**Trace Hierarchy:**\n",
    "```\n",
    "agent_conversation_workflow (custom)\n",
    "  â”œâ”€ threads.create (auto)\n",
    "  â”œâ”€ messages.create (auto)\n",
    "  â”œâ”€ runs.create_and_process (auto)\n",
    "  â”‚   â”œâ”€ chat.completions (auto)\n",
    "  â”‚   â””â”€ tool calls (if any)\n",
    "  â””â”€ messages.list (auto)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2bcf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traced_run_agent(project_client: AIProjectClient, agent_id: str, user_message: str):\n",
    "    \"\"\"Run an agent with Azure AI Foundry built-in tracing\"\"\"\n",
    "\n",
    "    with tracer.start_as_current_span(\n",
    "        \"agent_conversation_workflow\",\n",
    "        kind=SpanKind.CLIENT,\n",
    "        attributes={\n",
    "            \"agent.id\": agent_id,\n",
    "            \"workflow.type\": \"agent_execution\"\n",
    "        }\n",
    "    ) as workflow_span:\n",
    "        start_time = time.time()\n",
    "\n",
    "        try:\n",
    "            # Create thread - automatically traced\n",
    "            thread = project_client.agents.threads.create()\n",
    "            workflow_span.set_attribute(\"thread.id\", thread.id)\n",
    "\n",
    "            # Add message - automatically traced\n",
    "            project_client.agents.messages.create(\n",
    "                thread_id=thread.id,\n",
    "                role=\"user\",\n",
    "                content=user_message\n",
    "            )\n",
    "            workflow_span.set_attribute(\n",
    "                \"message.user_content_length\", len(user_message))\n",
    "\n",
    "            # Run agent - automatically traced with detailed spans\n",
    "            run = project_client.agents.runs.create_and_process(\n",
    "                thread_id=thread.id,\n",
    "                agent_id=agent_id\n",
    "            )\n",
    "\n",
    "            workflow_span.set_attribute(\"run.id\", run.id)\n",
    "            workflow_span.set_attribute(\"run.status\", run.status)\n",
    "\n",
    "            # Get messages - automatically traced\n",
    "            messages = list(\n",
    "                project_client.agents.messages.list(thread_id=thread.id))\n",
    "\n",
    "            # Extract assistant response\n",
    "            assistant_message = None\n",
    "            for msg in messages:\n",
    "                if msg.role == \"assistant\":\n",
    "                    assistant_message = msg.content[0].text.value\n",
    "                    break\n",
    "\n",
    "            total_latency = time.time() - start_time\n",
    "\n",
    "            workflow_span.set_attribute(\n",
    "                \"workflow.latency_ms\", total_latency * 1000)\n",
    "            workflow_span.set_attribute(\"workflow.success\", True)\n",
    "            if assistant_message:\n",
    "                workflow_span.set_attribute(\n",
    "                    \"message.assistant_content_length\", len(assistant_message))\n",
    "            workflow_span.set_status(Status(StatusCode.OK))\n",
    "\n",
    "            print(f\"âœ… Agent run completed\")\n",
    "            print(f\"   Thread ID: {thread.id}\")\n",
    "            print(f\"   Run ID: {run.id}\")\n",
    "            print(f\"   Status: {run.status}\")\n",
    "            print(f\"   Total latency: {total_latency*1000:.2f}ms\")\n",
    "            print(f\"\\nðŸ’¬ User: {user_message}\")\n",
    "            print(f\"ðŸ’¬ Assistant: {assistant_message}\")\n",
    "\n",
    "            return {\n",
    "                \"thread_id\": thread.id,\n",
    "                \"run_id\": run.id,\n",
    "                \"status\": run.status,\n",
    "                \"user_message\": user_message,\n",
    "                \"assistant_message\": assistant_message,\n",
    "                \"latency_ms\": total_latency * 1000\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            workflow_span.set_status(Status(StatusCode.ERROR, str(e)))\n",
    "            workflow_span.record_exception(e)\n",
    "            print(f\"âŒ Error running agent: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "# Example: Run the traced agent\n",
    "result = traced_run_agent(\n",
    "    project_client=project_client,\n",
    "    agent_id=test_agent.id,\n",
    "    user_message=\"What is Azure AI Foundry and its key features?\"\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ’¡ View detailed traces in Azure AI Foundry Portal:\")\n",
    "print(f\"   Filter by Run ID: {result['run_id']}\")\n",
    "print(f\"   Filter by Thread ID: {result['thread_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7de250",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Trace Function Calling\n",
    "\n",
    "Monitor agent tool/function calls with automatic instrumentation and custom spans for function execution.\n",
    "\n",
    "**Function Calling Workflow:**\n",
    "1. Agent requests function call (traced automatically)\n",
    "2. Function execution (add custom span for local execution)\n",
    "3. Submit function results (traced automatically)\n",
    "4. Agent processes results and generates response (traced automatically)\n",
    "\n",
    "**Custom Span Best Practices:**\n",
    "- Wrap local function execution in custom spans\n",
    "- Add function name, arguments, and results as attributes\n",
    "- Track execution duration and errors\n",
    "- Maintain parent-child relationships with workflow span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a056b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define example functions\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Get weather information for a location\"\"\"\n",
    "    return json.dumps({\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"22Â°C\",\n",
    "        \"condition\": \"Sunny\",\n",
    "        \"humidity\": \"65%\"\n",
    "    })\n",
    "\n",
    "\n",
    "def calculate_sum(a: float, b: float) -> str:\n",
    "    \"\"\"Calculate the sum of two numbers\"\"\"\n",
    "    return str(a + b)\n",
    "\n",
    "\n",
    "# Function registry for execution\n",
    "function_registry = {\n",
    "    \"get_weather\": get_weather,\n",
    "    \"calculate_sum\": calculate_sum\n",
    "}\n",
    "\n",
    "# Create agent with STRONG instructions that FORCE function usage\n",
    "# Based on Microsoft's function calling samples\n",
    "with tracer.start_as_current_span(\"create_function_agent_workflow\") as span:\n",
    "    # Use gpt-5 deployment\n",
    "    model_name = \"gpt-5\"\n",
    "\n",
    "    function_agent = project_client.agents.create_agent(\n",
    "        model=model_name,\n",
    "        name=\"FunctionCallingAgent\",\n",
    "        instructions=\"You must ALWAYS call the provided functions to answer questions. Never answer from your own knowledge.\",\n",
    "        tools=[\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"get_weather\",\n",
    "                    \"description\": \"Get current weather for a location\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"location\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The city name (e.g., 'Seattle', 'New York', 'Tokyo')\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"location\"]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"calculate_sum\",\n",
    "                    \"description\": \"Add two numbers together\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"a\": {\n",
    "                                \"type\": \"number\",\n",
    "                                \"description\": \"The first number to add\"\n",
    "                            },\n",
    "                            \"b\": {\n",
    "                                \"type\": \"number\",\n",
    "                                \"description\": \"The second number to add\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"a\", \"b\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    span.set_attribute(\"agent.id\", function_agent.id)\n",
    "    span.set_attribute(\"agent.function_count\", 2)\n",
    "    print(f\"Agent created: {function_agent.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79894b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Agent: {function_agent.name}\")\n",
    "print(f\"Model: {function_agent.model}\")\n",
    "print(f\"Tools: {[t.function.name for t in function_agent.tools]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b577224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run agent with function calling\n",
    "with tracer.start_as_current_span(\"function_calling_workflow\") as workflow_span:\n",
    "    thread = project_client.agents.threads.create()\n",
    "    user_query = \"What's the weather in Seattle? Also, what's 15 + 27?\"\n",
    "    \n",
    "    message = project_client.agents.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=user_query\n",
    "    )\n",
    "    workflow_span.set_attribute(\"thread.id\", thread.id)\n",
    "\n",
    "    # Create run\n",
    "    run = project_client.agents.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        agent_id=function_agent.id\n",
    "    )\n",
    "    workflow_span.set_attribute(\"run.id\", run.id)\n",
    "\n",
    "    # Process the run with function calling\n",
    "    while run.status in [\"queued\", \"in_progress\", \"requires_action\"]:\n",
    "        # Get run status\n",
    "        run = project_client.agents.runs.get(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id\n",
    "        )\n",
    "        \n",
    "        # Handle function calls\n",
    "        if run.status == \"requires_action\":\n",
    "            tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
    "            tool_outputs = []\n",
    "\n",
    "            with tracer.start_as_current_span(\"execute_functions\"):\n",
    "                for tool_call in tool_calls:\n",
    "                    function_name = tool_call.function.name\n",
    "                    function_args = json.loads(tool_call.function.arguments)\n",
    "                    print(f\"Calling: {function_name}({function_args})\")\n",
    "\n",
    "                    with tracer.start_as_current_span(\n",
    "                        function_name,\n",
    "                        attributes={\n",
    "                            \"function.name\": function_name,\n",
    "                            \"function.arguments\": json.dumps(function_args)\n",
    "                        }\n",
    "                    ) as func_span:\n",
    "                        func = function_registry[function_name]\n",
    "                        result = func(**function_args)\n",
    "                        func_span.set_attribute(\"function.result\", str(result))\n",
    "                        func_span.set_status(Status(StatusCode.OK))\n",
    "                        tool_outputs.append({\n",
    "                            \"tool_call_id\": tool_call.id,\n",
    "                            \"output\": result\n",
    "                        })\n",
    "                        print(f\"Result: {result}\")\n",
    "\n",
    "            # Submit function results\n",
    "            project_client.agents.runs.submit_tool_outputs(\n",
    "                thread_id=thread.id,\n",
    "                run_id=run.id,\n",
    "                tool_outputs=tool_outputs\n",
    "            )\n",
    "\n",
    "    # Get the final response\n",
    "    messages = project_client.agents.messages.list(thread_id=thread.id)\n",
    "\n",
    "    print(f\"\\nðŸ¤– Response:\")\n",
    "    print(\"=\" * 80)\n",
    "    for msg in messages:\n",
    "        if msg.role == \"assistant\":\n",
    "            if msg.text_messages:\n",
    "                for text_msg in msg.text_messages:\n",
    "                    print(text_msg.text.value)\n",
    "            break\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    workflow_span.set_status(Status(StatusCode.OK))\n",
    "\n",
    "trace.get_tracer_provider().force_flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ed0f6b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: View Traces in Azure Portal\n",
    "\n",
    "Access and analyze traces through Azure AI Foundry Portal and Application Insights.\n",
    "\n",
    "**Azure AI Foundry Portal (ai.azure.com):**\n",
    "- Navigate to your project â†’ Tracing tab\n",
    "- View agent runs, messages, and tool calls\n",
    "- Interactive trace hierarchy visualization\n",
    "- Filter by agent ID, thread ID, or time range\n",
    "- Performance metrics and success rates\n",
    "\n",
    "**Application Insights Portal:**\n",
    "- Comprehensive telemetry dashboard\n",
    "- Real-time monitoring with Live Metrics\n",
    "- Custom KQL queries for deep analysis\n",
    "- Alerts and automated notifications\n",
    "- Workbooks for custom visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55adcfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ðŸ“Š VIEWING TRACES IN AZURE AI FOUNDRY PORTAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nðŸŒ Azure AI Foundry Portal:\")\n",
    "print(\"   1. Navigate to https://ai.azure.com\")\n",
    "print(\"   2. Select your project\")\n",
    "print(\"   3. Go to 'Tracing' in the left menu\")\n",
    "print(\"   4. View traces for all agent operations\")\n",
    "\n",
    "print(\"\\nðŸ” What's Automatically Traced:\")\n",
    "print(\"   âœ… Agent creation and configuration\")\n",
    "print(\"   âœ… Thread creation and management\")\n",
    "print(\"   âœ… Message creation (user and assistant)\")\n",
    "print(\"   âœ… Agent runs and execution\")\n",
    "print(\"   âœ… Function/tool calls and results\")\n",
    "print(\"   âœ… Token usage and costs\")\n",
    "print(\"   âœ… Latency for each operation\")\n",
    "print(\"   âœ… Errors and exceptions\")\n",
    "\n",
    "print(\"\\nðŸ“‹ Trace Details Include:\")\n",
    "print(\"   - Span hierarchy (parent-child relationships)\")\n",
    "print(\"   - Timestamps and duration\")\n",
    "print(\"   - Input/output content (if content recording enabled)\")\n",
    "print(\"   - Model parameters (temperature, max_tokens, etc.)\")\n",
    "print(\"   - Function arguments and return values\")\n",
    "print(\"   - Status codes and error messages\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Application Insights:\")\n",
    "print(\"   - Traces are also available in Azure Monitor\")\n",
    "print(\"   - Query using KQL (Kusto Query Language)\")\n",
    "print(\"   - Set up dashboards and alerts\")\n",
    "print(\"   - Analyze performance trends\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a8702f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Monitoring Best Practices\n",
    "\n",
    "Follow these guidelines for effective agent monitoring and observability.\n",
    "\n",
    "### Content Recording Configuration\n",
    "\n",
    "**Enable Content Recording:**\n",
    "```python\n",
    "os.environ[\"AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED\"] = \"true\"\n",
    "```\n",
    "\n",
    "**Considerations:**\n",
    "- âš ï¸ May capture personal data (PII) in prompts/responses\n",
    "- Review compliance requirements (GDPR, HIPAA, etc.)\n",
    "- Consider data residency and retention policies\n",
    "- Use for debugging/development, disable for production if needed\n",
    "\n",
    "### Performance Monitoring\n",
    "\n",
    "**Key Metrics to Track:**\n",
    "- **Latency**: P50, P95, P99 percentiles for operations\n",
    "- **Success Rate**: Percentage of successful runs\n",
    "- **Token Usage**: Prompt/completion tokens per operation\n",
    "- **Error Rate**: Failed operations and exception types\n",
    "- **Throughput**: Requests per minute/hour\n",
    "\n",
    "**Set Up Alerts:**\n",
    "- Error rate exceeds threshold (e.g., > 5%)\n",
    "- Average latency exceeds SLA (e.g., > 5 seconds)\n",
    "- Token usage spikes unexpectedly\n",
    "- Application Insights connection failures\n",
    "\n",
    "### Cost Optimization\n",
    "\n",
    "**Monitor Token Consumption:**\n",
    "```kql\n",
    "dependencies\n",
    "| where name contains \"chat.completions\"\n",
    "| extend total_tokens = toint(customDimensions.[\"gen_ai.usage.total_tokens\"])\n",
    "| summarize total_tokens_per_day = sum(total_tokens) by bin(timestamp, 1d)\n",
    "```\n",
    "\n",
    "**Optimization Strategies:**\n",
    "- Identify prompts with high token counts\n",
    "- Optimize system instructions for brevity\n",
    "- Use prompt caching where appropriate\n",
    "- Monitor and limit max_tokens parameter\n",
    "\n",
    "### Debugging Workflows\n",
    "\n",
    "**Use Operation IDs:**\n",
    "- Every trace has a unique `operation_Id`\n",
    "- Correlates all spans in a single request\n",
    "- Use to reconstruct complete conversation flow\n",
    "\n",
    "**Filter by Agent/Thread:**\n",
    "```kql\n",
    "dependencies\n",
    "| where customDimensions.[\"gen_ai.agent.id\"] == \"<agent_id>\"\n",
    "| where customDimensions.[\"gen_ai.thread.id\"] == \"<thread_id>\"\n",
    "```\n",
    "\n",
    "### Production Readiness\n",
    "\n",
    "**Before Going to Production:**\n",
    "- âœ… Configure Application Insights retention (default: 90 days)\n",
    "- âœ… Set up critical alerts (errors, latency, costs)\n",
    "- âœ… Create operational dashboards for stakeholders\n",
    "- âœ… Test trace export with production load\n",
    "- âœ… Document KQL queries for common scenarios\n",
    "- âœ… Establish baseline metrics for comparison\n",
    "- âœ… Review content recording compliance\n",
    "\n",
    "**Cleanup Test Resources:**\n",
    "- Delete test agents and threads after experiments\n",
    "- Avoid polluting production telemetry with test data\n",
    "- Use separate Azure AI projects for dev/staging/prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95681381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup test agents\n",
    "try:\n",
    "    if 'test_agent' in locals() and test_agent.id:\n",
    "        project_client.agents.delete(test_agent.id)\n",
    "        print(f\"âœ… Deleted agent: {test_agent.id}\")\n",
    "    \n",
    "    if 'function_agent' in locals() and function_agent.id:\n",
    "        project_client.agents.delete(function_agent.id)\n",
    "        print(f\"âœ… Deleted agent: {function_agent.id}\")\n",
    "    \n",
    "    if 'thread' in locals() and thread.id:\n",
    "        project_client.agents.threads.delete(thread.id)\n",
    "        print(f\"âœ… Deleted thread: {thread.id}\")\n",
    "        \n",
    "    print(\"\\nðŸ§¹ Cleanup complete!\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Cleanup warning: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47d0aa9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary and Best Practices\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Zero-Code Instrumentation**: Azure AI Foundry SDK automatically traces all operations\n",
    "2. **Complete Observability**: Full visibility into agents, LLMs, and tool calls\n",
    "3. **Production-Ready**: Built-in export to Application Insights with retry/buffering\n",
    "4. **Rich Analytics**: KQL queries, dashboards, and alerts in Azure Portal\n",
    "5. **Content Recording**: Opt-in prompt/response capture for debugging\n",
    "\n",
    "### What Gets Automatically Traced\n",
    "\n",
    "**Agent Operations:**\n",
    "- `agents.create_agent()` - Creation with model config\n",
    "- `threads.create()` - Thread initialization\n",
    "- `messages.create()` - User/assistant messages\n",
    "- `runs.create_and_process()` - Complete execution\n",
    "- `runs.submit_tool_outputs()` - Function results\n",
    "- `messages.list()` - Message retrieval\n",
    "\n",
    "**LLM Interactions:**\n",
    "- Model name, deployment, version\n",
    "- Token usage (prompt, completion, total)\n",
    "- Request/response latency\n",
    "- Parameters (temperature, max_tokens, etc.)\n",
    "- Success/failure status codes\n",
    "- Content (if recording enabled)\n",
    "\n",
    "**Tool/Function Calls:**\n",
    "- Function name and description\n",
    "- Input arguments (JSON)\n",
    "- Return values\n",
    "- Execution duration\n",
    "- Error messages and stack traces\n",
    "\n",
    "**Context & Metadata:**\n",
    "- Operation IDs (trace correlation)\n",
    "- Agent IDs, thread IDs, run IDs\n",
    "- Custom dimensions and attributes\n",
    "- Parent-child span relationships\n",
    "- Timestamps and durations\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "#### 1. Tracing Configuration\n",
    "- âœ… Enable content recording for development/debugging\n",
    "- âœ… Review compliance before enabling in production (PII concerns)\n",
    "- âœ… Use Application Insights connection string from Azure AI Project\n",
    "- âœ… Suppress verbose SDK logging for cleaner output\n",
    "- âœ… Call `force_flush()` before notebook/script ends\n",
    "\n",
    "#### 2. Custom Spans (Optional)\n",
    "- âœ… Add workflow-level spans for business logic\n",
    "- âœ… Use descriptive span names (e.g., \"agent_conversation_workflow\")\n",
    "- âœ… Set `SpanKind.CLIENT` for client operations\n",
    "- âœ… Add custom attributes for filtering and analysis\n",
    "- âœ… Record exceptions with `span.record_exception(e)`\n",
    "- âœ… Set span status: `Status(StatusCode.OK)` or `Status(StatusCode.ERROR)`\n",
    "\n",
    "#### 3. Performance Monitoring\n",
    "- âœ… Track latency percentiles (P50, P95, P99)\n",
    "- âœ… Monitor success rates and error rates\n",
    "- âœ… Calculate token usage and costs per day/week\n",
    "- âœ… Identify slow operations for optimization\n",
    "- âœ… Set up alerts for SLA violations\n",
    "\n",
    "#### 4. Cost Management\n",
    "- âœ… Query token usage trends with KQL\n",
    "- âœ… Identify high-cost prompts and optimize\n",
    "- âœ… Monitor daily/weekly spending patterns\n",
    "- âœ… Use prompt caching to reduce repeated calls\n",
    "- âœ… Set budget alerts in Azure Cost Management\n",
    "\n",
    "#### 5. Debugging and Troubleshooting\n",
    "- âœ… Use operation IDs to trace complete conversations\n",
    "- âœ… Filter by agent ID or thread ID for specific issues\n",
    "- âœ… Review exception messages and stack traces\n",
    "- âœ… Check content recording for prompt/response debugging\n",
    "- âœ… Compare traces before/after changes\n",
    "\n",
    "#### 6. Production Readiness\n",
    "- âœ… Configure Application Insights data retention (default: 90 days)\n",
    "- âœ… Set up critical alerts (errors > 5%, latency > SLA)\n",
    "- âœ… Create dashboards for stakeholders\n",
    "- âœ… Test trace export under production load\n",
    "- âœ… Document common KQL queries\n",
    "- âœ… Establish baseline metrics\n",
    "- âœ… Use separate projects for dev/staging/prod\n",
    "- âœ… Review content recording compliance requirements\n",
    "\n",
    "### Common KQL Queries Summary\n",
    "\n",
    "| Query Purpose | Key Fields |\n",
    "|---------------|-----------|\n",
    "| All agent operations | `dependencies` table, `name`, `timestamp` |\n",
    "| Latency analysis | `duration`, `percentile()`, `avg()` |\n",
    "| Token usage & costs | `gen_ai.usage.total_tokens`, `sum()` |\n",
    "| Error tracking | `success == false`, `exception.type` |\n",
    "| Function calls | `gen_ai.tool.name`, `count()` |\n",
    "| Conversation flows | `operation_Id`, `operation_ParentId` |\n",
    "| Performance by model | `gen_ai.request.model`, `avg(duration)` |\n",
    "\n",
    "### Azure Portal Dashboards\n",
    "\n",
    "**Azure AI Foundry Portal (ai.azure.com):**\n",
    "- Tracing tab: Agent runs, messages, tool calls\n",
    "- Performance metrics: Latency, success rates, token usage\n",
    "- Conversation flows: Interactive trace hierarchy\n",
    "- Filter & search: By agent, thread, time range\n",
    "\n",
    "**Application Insights Portal:**\n",
    "- Application Map: Service topology visualization\n",
    "- Performance: Latency distribution, slow operations\n",
    "- Failures: Error rates, exception details\n",
    "- Live Metrics: Real-time monitoring dashboard\n",
    "- Workbooks: Custom visualizations with KQL\n",
    "\n",
    "### Integration Patterns\n",
    "\n",
    "**CI/CD Quality Gates:**\n",
    "```yaml\n",
    "# Example: Check error rate before deployment\n",
    "- name: Validate Agent Quality\n",
    "  run: |\n",
    "    error_rate=$(az monitor app-insights query \\\n",
    "      --analytics-query \"dependencies | where timestamp > ago(24h) | summarize error_rate=100.0*countif(success==false)/count()\" \\\n",
    "      --output tsv)\n",
    "    if [ $error_rate -gt 5 ]; then exit 1; fi\n",
    "```\n",
    "\n",
    "**Automated Alerts:**\n",
    "- Error rate > 5% â†’ PagerDuty/Teams notification\n",
    "- P95 latency > 5s â†’ Email to on-call engineer\n",
    "- Token usage spikes > 2x baseline â†’ Slack alert\n",
    "- Application Insights connection failures â†’ Incident\n",
    "\n",
    "**Dashboard Automation:**\n",
    "- Daily token usage report â†’ Email stakeholders\n",
    "- Weekly performance summary â†’ Management dashboard\n",
    "- Real-time cost tracking â†’ Finance dashboard\n",
    "- Agent adoption metrics â†’ Product analytics\n",
    "\n",
    "### Troubleshooting Guide\n",
    "\n",
    "| Issue | Possible Cause | Solution |\n",
    "|-------|---------------|----------|\n",
    "| No traces appearing | App Insights not configured | Verify connection string, check `configure_azure_monitor()` |\n",
    "| Missing content | Recording disabled | Set `AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED=true` |\n",
    "| High trace volume | All operations traced | Normal behavior; use KQL filters to focus |\n",
    "| Traces delayed | Buffering/network latency | Wait 1-2 minutes; call `force_flush()` for immediate export |\n",
    "| Token fields empty | Not an LLM operation | Only `chat.completions` spans have token data |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Enable Tracing**: Configure Azure Monitor in your agent code\n",
    "2. **Run Workloads**: Execute typical agent operations\n",
    "3. **Explore Portal**: View traces in Azure AI Foundry and App Insights\n",
    "4. **Create Queries**: Build KQL queries for your use cases\n",
    "5. **Set Up Alerts**: Configure notifications for critical issues\n",
    "6. **Build Dashboards**: Create visualizations for stakeholders\n",
    "7. **Monitor Costs**: Track token usage and optimize prompts\n",
    "8. **Iterate**: Use insights to improve agent performance\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [Azure AI Foundry Tracing Documentation](https://learn.microsoft.com/azure/ai-foundry/how-to/develop/trace-agents-sdk)\n",
    "- [OpenTelemetry Python SDK](https://opentelemetry.io/docs/instrumentation/python/)\n",
    "- [Azure Monitor OpenTelemetry](https://learn.microsoft.com/azure/azure-monitor/app/opentelemetry-enable)\n",
    "- [KQL Query Language Reference](https://learn.microsoft.com/azure/data-explorer/kusto/query/)\n",
    "- [Application Insights Overview](https://learn.microsoft.com/azure/azure-monitor/app/app-insights-overview)\n",
    "\n",
    "### Related Notebooks\n",
    "\n",
    "- `01_agent/01_basic_agent.ipynb`: Create and run agents\n",
    "- `05_evaluation/01_genai_evaluation.ipynb`: Local agent evaluation\n",
    "- `05_evaluation/05_cloud_based_evaluation.ipynb`: Cloud-based evaluation\n",
    "- `02_governance/`: Agent governance and compliance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
