{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent Collaboration \n",
    "---\n",
    "\n",
    "### What is Multi-Agent Collaboration?\n",
    "Multi-Agent Collaboration refers to the process where multiple autonomous agents—each capable of independent decision-making—work together to achieve common or complementary objectives. This concept is widely used in fields like artificial intelligence, robotics, distributed computing, and simulation, and it involves several key aspects:\n",
    "\n",
    "- **Effective Communication and Coordination**:\n",
    "Agents exchange information and align their actions to collectively achieve a goal, ensuring that tasks are organized and synchronized.\n",
    "\n",
    "- **Autonomous, Distributed Decision-Making**:\n",
    "Each agent operates independently, making local decisions while contributing to a broader strategy, which enhances flexibility and fault tolerance.\n",
    "\n",
    "- **Adaptive Task Specialization**:\n",
    "Agents focus on specific roles or subtasks based on their capabilities, and they adjust their strategies through iterative feedback, leading to improved overall performance.\n",
    "\n",
    "\n",
    "### Key Advantages\n",
    "- **Efficiency Through Task Specialization**:\n",
    "By assigning specific roles to different agents, the system can handle complex tasks in parallel. This specialization allows each agent to focus on its area of expertise, resulting in faster and more effective problem-solving.\n",
    "\n",
    "- **Scalability and Flexibility**:\n",
    "AutoGen's structured communication and dynamic task allocation enable the system to scale easily. It can adapt to varying project complexities by adding or reassigning agents as needed, ensuring that the collaboration remains robust even as demands change.\n",
    "\n",
    "- **Enhanced Iterative Refinement**:\n",
    "The framework’s built-in feedback loops and iterative dialogue facilitate continuous improvement. Agents can refine their outputs based on real-time feedback, leading to more accurate and cohesive final results.\n",
    "\n",
    "**Reference**\n",
    "- [AutoGen paper: Enabling Next-Gen LLM Applications via Multi-Agent Conversation](https://arxiv.org/abs/2308.08155)\n",
    "- [Multi-Agent Collabration Concept](https://langchain-ai.github.io/langgraph/concepts/multi_agent/#network) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"autogen-core\"==0.4.5 -qU\n",
    "%pip install \"autogen-ext[openai,azure]\"==0.4.5 -qU\n",
    "%pip install \"autogen-agentchat\"==0.4.5 -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen_agentchat as chat\n",
    "\n",
    "chat.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(os.getenv('CHAT_MODEL'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(), conn_str=os.environ[\"AIPROJECT_CONNECTION_STRING\"]\n",
    ")\n",
    "\n",
    "base_url = project_client.inference.get_azure_openai_client(\n",
    "    api_version=\"2024-06-01\").base_url\n",
    "\n",
    "api_endpoint = f'https://{base_url.host}/'\n",
    "\n",
    "api_key = project_client.inference.get_azure_openai_client(\n",
    "    api_version=\"2024-06-01\").api_key\n",
    "\n",
    "deployment_name = os.environ[\"CHAT_MODEL\"]\n",
    "\n",
    "aoai_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_endpoint=api_endpoint,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    azure_deployment=deployment_name,\n",
    "    api_key=api_key,\n",
    "    api_version=\"2024-06-01\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "\n",
    "\n",
    "# Define a tool\n",
    "async def get_weather(city: str) -> str:\n",
    "    return f\"The weather in {city} is 73 degrees and Sunny.\"\n",
    "\n",
    "\n",
    "async def main() -> None:\n",
    "    # Define an agent\n",
    "    weather_agent = AssistantAgent(\n",
    "        name=\"weather_agent\",\n",
    "        model_client=aoai_client,\n",
    "        tools=[get_weather],\n",
    "    )\n",
    "\n",
    "    # Define termination condition\n",
    "    termination = TextMentionTermination(\"TERMINATE\")\n",
    "\n",
    "    # Define a team\n",
    "    agent_team = RoundRobinGroupChat(\n",
    "        [weather_agent], termination_condition=termination)\n",
    "\n",
    "    # Run the team and stream messages to the console\n",
    "    stream = agent_team.run_stream(task=\"What is the weather in New York?\")\n",
    "    await Console(stream)\n",
    "\n",
    "\n",
    "# NOTE: if running this inside a Python script you'll need to use asyncio.run(main()).\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "The code snippet above introduces two high level concepts in AgentChat: Agent and Team. An Agent helps us define what actions are taken when a message is received. Specifically, we use the AssistantAgent preset - an agent that can be given access to a model (e.g., LLM) and tools (functions) that it can then use to address tasks. A Team helps us define the rules for how agents interact with each other. In the RoundRobinGroupChat team, agents respond in a sequential round-robin fashion. In this case, we have a single agent, so the same agent is used for each round."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
